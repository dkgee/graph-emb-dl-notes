# 贡献指南

> 请您勇敢地去翻译和改进翻译。虽然我们追求卓越，但我们并不要求您做到十全十美，因此请不要担心因为翻译上犯错——在大部分情况下，我们的服务器已经记录所有的翻译，因此您不必担心会因为您的失误遭到无法挽回的破坏。（改编自维基百科）

负责人：

+   [飞龙](https://github.com/wizardforcel)：562826179

## 章节列表

+   GCN
    +   [A new model for learning in graph domains](https://ieeexplore.ieee.org/abstract/document/1555942)
    +   [The graph neural network model](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.1015.7227&rep=rep1&type=pdf)
    +   [Spectral networks and locally connected networks on graphs](https://arxiv.org/pdf/1312.6203.pdf)
    +   [Convolutional networks on graphs for learning molecular fingerprints](http://papers.nips.cc/paper/5954-convolutional-networks-on-graphs-for-learning-molecular-fingerprints.pdf)
    +   [Gated graph sequence neural networks](https://arxiv.org/pdf/1511.05493.pdf)
    +   [Accelerated filtering on graphs using lanczos method](https://arxiv.org/pdf/1509.04537.pdf)
    +   [Deep convolutional networks on graph-structured data](https://arxiv.org/abs/1506.05163) 
    +   [Convolutional neural networks on graphs with fast localized spectral filtering](https://arxiv.org/pdf/1606.09375.pdf)
    +   [Diffusion-convolutional neural networks](https://arxiv.org/pdf/1511.02136.pdf)
    +   [Learning convolutional neural networks for graphs](https://arxiv.org/pdf/1605.05273.pdf)
    +   [Molecular graph convolutions: moving beyond fingerprints](https://arxiv.org/pdf/1603.00856.pdf)
    +   [Inductive representation learning on large graphs](http://papers.nips.cc/paper/6703-inductive-representation-learning-on-large-graphs.pdf)
    +   [Neural message passing for quantum chemistry](https://arxiv.org/pdf/1704.01212.pdf)
    +   [Dynamic Edge-Conditioned Filters in Convolutional Neural Networks on Graphs](https://arxiv.org/pdf/1704.02901.pdf) 
    +   [Geometric deep learning on graphs and manifolds using mixture model cnns](https://arxiv.org/pdf/1611.08402.pdf)
    +   [Semi-supervised classification with graph convolutional networks](https://arxiv.org/pdf/1609.02907.pdf)
    +   [Robust spatial filtering with graph convolutional neural networks](https://arxiv.org/abs/1703.00792)
    +   [Cayleynets: graph convolutional neural networks with complex rational spectral filters](https://arxiv.org/pdf/1705.07664.pdf)
    +   [Hierarchical graph representation learning with differentiable pooling](https://arxiv.org/pdf/1806.08804.pdf)
    +   [Structure-Aware Convolutional Neural Networks](http://papers.nips.cc/paper/7287-structure-aware-convolutional-neural-networks.pdf)
    +   [Adaptive graph convolutional neural networks](https://arxiv.org/pdf/1801.03226.pdf)
    +   [Deeper insights into graph convolutional networks for semi-supervised learning](https://arxiv.org/pdf/1801.07606.pdf)
    +   [Large-Scale Learnable Graph Convolutional Networks](https://arxiv.org/pdf/1808.03965.pdf)
    +   [FastGCN: Fast Learning with Graph Convolutional Networks via Importance Sampling](https://arxiv.org/pdf/1801.10247.pdf)
    +   [Learning steady-states of iterative algorithms over graphs](http://proceedings.mlr.press/v80/dai18a/dai18a.pdf)
    +   [Representation learning on graphs with jumping knowledge networks](https://arxiv.org/pdf/1806.03536.pdf)
    +   [Stochastic Training of Graph Convolutional Networks with Variance Reduction](https://arxiv.org/pdf/1710.10568.pdf)
    +   [Dual graph convolutional networks for graph-based semi-supervised classification](http://delivery.acm.org/10.1145/3190000/3186116/p499-zhuang.pdf?ip=1.129.110.137&id=3186116&acc=OPEN&key=4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E6D218144511F3437&__acm__=1546208231_ba22bb40f3bc41441d1fea0606eb8adb)
    +   [Graph capsule convolutional neural networks](https://arxiv.org/abs/1805.08090)
    +   [How powerful are graph neural networks?](https://arxiv.org/pdf/1810.00826.pdf)
    +   [Modeling relational data with graph convolutional networks](https://arxiv.org/pdf/1703.06103.pdf)
    +   [Multidimensional graph convolutional networks](https://arxiv.org/pdf/1808.06099.pdf)
    +   [Signed graph convolutional network](https://arxiv.org/pdf/1808.06354.pdf)
    +   [Capsule Graph Neural Network](https://openreview.net/pdf?id=Byl8BnRcYm)
    +   [Combining Neural Networks with Personalized PageRank for Classification on Graphs](https://openreview.net/pdf?id=H1gL-2A9Ym)
    +   [DIFFUSION SCATTERING TRANSFORMS ON GRAPHS](https://arxiv.org/pdf/1806.08829.pdf)
    +   [Graph Wavelet Neural Network](https://openreview.net/pdf?id=H1ewdiR5tQ)
    +   [LanczosNet: Multi-Scale Deep Graph Convolutional Networks](https://openreview.net/pdf?id=BkedznAqKQ)
    +   [Bayesian Graph Convolutional Neural Networks for Semi-supervised Classification](https://arxiv.org/pdf/1811.11103.pdf)
    +   [Geniepath: Graph neural networks with adaptive receptive paths](https://arxiv.org/pdf/1802.00910.pdf)
    +   [Hypergraph Neural Networks](https://arxiv.org/pdf/1809.09401.pdf)
    +   [Weisfeiler and Leman Go Neural: Higher-order Graph Neural Networks](https://arxiv.org/pdf/1810.02244.pdf)
    +   [Can GCNs Go as Deep as CNNs?](https://arxiv.org/abs/1904.03751)
+   Graph Attention
    +   [Graph Attention Networks](https://arxiv.org/pdf/1710.10903.pdf)
    +   [Gaan: Gated attention networks for learning on large and spatiotemporal graphs](https://arxiv.org/pdf/1803.07294.pdf)
    +   [Watch your step: Learning node embeddings via graph attention](https://arxiv.org/pdf/1710.09599.pdf)
    +   [Graph classification using structural attention](https://dl.acm.org/citation.cfm?id=3219980)
+   GAE
    +   [Structural deep network embedding](https://www.kdd.org/kdd2016/papers/files/rfp0191-wangAemb.pdf)
    +   [Deep neural networks for learning graph representations](https://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/view/12423/11715)
    +   [Variational graph auto-encoders](https://arxiv.org/pdf/1611.07308.pdf)
    +   [Mgae: Marginalized graph autoencoder for graph clustering](https://shiruipan.github.io/pdf/CIKM-17-Wang.pdf)
    +   [Link Prediction Based on Graph Neural Networks](https://arxiv.org/pdf/1802.09691.pdf)
    +   [SpectralNet: Spectral Clustering using Deep Neural Networks](https://arxiv.org/pdf/1801.01587.pdf)
    +   [Deep Recursive Network Embedding with Regular Equivalence](http://cuip.thumedialab.com/papers/NE-RegularEquivalence.pdf)
    +   [Learning Deep Network Representations with Adversarially Regularized Autoencoders](http://www.cs.ucsb.edu/~bzong/doc/kdd-18.pdf)
    +   [Adversarially Regularized Graph Autoencoder for Graph Embedding](https://www.ijcai.org/proceedings/2018/0362.pdf)
    +   [Deep graph infomax](https://arxiv.org/abs/1809.10341)

## 流程

### 一、认领

首先查看[整体进度](https://github.com/apachecn/stanford-cs224n-notes-zh/issues/1)，确认没有人认领了你想认领的章节。
 
然后回复 ISSUE，注明“章节 + QQ 号”。

### 二、整理笔记

阅读论文，填写以下内容：

+   模型架构
+   输入类型：同构图/二分图
+   嵌入类型：节点/边/子图/整图
+   任务类型：无监督/半监督
+   和 baseline 相比的创新点
+   （有/无）理论解释

### 三、提交

+   `fork` Github 项目
+   将文档（**Markdown 格式**）放在`docs`中。
+   `push`
+   `pull request`

请见 [Github 入门指南](https://github.com/apachecn/kaggle/blob/master/docs/GitHub)。
